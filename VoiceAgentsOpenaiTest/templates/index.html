<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Voice Agent - Press Space to Talk</title>

    <!-- Three.js imports -->
    <script type="importmap">
    {
      "imports": {
        "three": "https://unpkg.com/three@0.160.0/build/three.module.js",
        "three/addons/": "https://unpkg.com/three@0.160.0/examples/jsm/"
      }
    }
    </script>

    <style>
        * {
            margin: 0;
            padding: 0;
            box-sizing: border-box;
        }

        html {
            margin: 0;
            height: 100%;
            background: #101014;
        }

        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: none;
            min-height: 100vh;
            display: flex;
            flex-direction: row;
            align-items: flex-start;
            justify-content: center;
            padding: 20px;
            gap: 20px;
        }

        /* 3D canvas background */
        #three-container {
            width: 100%;
            height: 100%;
            flex: 0 1 auto;
        }

        #three-canvas {
            width: 100%;
            height: 100%;
            min-height: 730px;
            display: block;
            border-radius: 20px;
        }

        .container {
            background: rgba(255, 255, 255, 0.95);
            border-radius: 20px;
            box-shadow: 0 20px 60px rgba(0, 0, 0, 0.3);
            padding: 40px;
            max-width: 800px;
            width: 100%;
            position: relative;
            z-index: 1;
            opacity: 1;
            transform: scale(1);
            transition: opacity 0.3s ease, transform 0.3s ease;
        }

        .container.hidden {
            opacity: 0;
            transform: scale(0.95);
            pointer-events: none;
        }

        h1 {
            text-align: center;
            color: #333;
            margin-bottom: 10px;
            font-size: 2em;
        }

        .subtitle {
            text-align: center;
            color: #666;
            margin-bottom: 30px;
            font-size: 1.1em;
        }

        .status-indicator {
            display: flex;
            align-items: center;
            justify-content: center;
            margin-bottom: 30px;
            padding: 20px;
            border-radius: 10px;
            background: #f5f5f5;
            transition: all 0.3s ease;
        }

        .status-indicator.recording {
            background: #ffebee;
            border: 2px solid #ef5350;
        }

        .status-indicator.processing {
            background: #e3f2fd;
            border: 2px solid #42a5f5;
        }

        .status-dot {
            width: 12px;
            height: 12px;
            border-radius: 50%;
            background: #9e9e9e;
            margin-right: 10px;
            transition: all 0.3s ease;
        }

        .status-indicator.recording .status-dot {
            background: #ef5350;
            animation: pulse 1s ease-in-out infinite;
        }

        .status-indicator.processing .status-dot {
            background: #42a5f5;
            animation: spin 1s linear infinite;
        }

        @keyframes pulse {
            0%, 100% { transform: scale(1); opacity: 1; }
            50% { transform: scale(1.2); opacity: 0.7; }
        }

        @keyframes spin {
            from { transform: rotate(0deg); }
            to { transform: rotate(360deg); }
        }

        .status-text {
            font-size: 1.1em;
            color: #333;
            font-weight: 500;
        }

        .transcription-box {
            background: #fff9e6;
            border: 2px solid #ffd54f;
            border-radius: 10px;
            padding: 15px;
            margin-bottom: 20px;
            min-height: 60px;
            display: none;
        }

        .transcription-box.show {
            display: block;
        }

        .transcription-label {
            font-size: 0.9em;
            color: #f57c00;
            font-weight: 600;
            margin-bottom: 8px;
        }

        .transcription-text {
            font-size: 1.1em;
            color: #333;
            line-height: 1.5;
        }

        .transcription-text.interim {
            color: #999;
            font-style: italic;
        }

        .chat-container {
            background: #f9f9f9;
            border-radius: 10px;
            padding: 20px;
            min-height: 300px;
            max-height: 400px;
            overflow-y: auto;
            margin-bottom: 20px;
        }

        .message {
            margin-bottom: 15px;
            padding: 12px 16px;
            border-radius: 8px;
            max-width: 80%;
            word-wrap: break-word;
        }

        .message.user {
            background: #667eea;
            color: white;
            margin-left: auto;
            text-align: right;
        }

        .message.assistant {
            background: white;
            color: #333;
            border: 1px solid #e0e0e0;
        }

        .message-label {
            font-size: 0.8em;
            opacity: 0.7;
            margin-bottom: 5px;
            font-weight: 600;
        }

        .message-content {
            line-height: 1.5;
        }

        .instructions {
            text-align: center;
            padding: 20px;
            background: #f0f0f0;
            border-radius: 10px;
            margin-bottom: 20px;
        }

        .instructions kbd {
            background: #333;
            color: white;
            padding: 5px 10px;
            border-radius: 5px;
            font-family: monospace;
            font-size: 1.1em;
            box-shadow: 0 2px 4px rgba(0,0,0,0.2);
        }

        .controls {
            display: flex;
            justify-content: center;
            gap: 10px;
            margin-top: 20px;
        }

        .btn {
            padding: 12px 24px;
            border: none;
            border-radius: 8px;
            font-size: 1em;
            cursor: pointer;
            transition: all 0.3s ease;
            font-weight: 600;
        }

        .btn-reset {
            background: #ef5350;
            color: white;
        }

        .btn-reset:hover {
            background: #d32f2f;
            transform: translateY(-2px);
            box-shadow: 0 4px 8px rgba(0,0,0,0.2);
        }

        .error {
            background: #ffebee;
            color: #c62828;
            padding: 12px;
            border-radius: 8px;
            margin-top: 10px;
            display: none;
        }

        .error.show {
            display: block;
        }

        /* Scrollbar styling */
        .chat-container::-webkit-scrollbar {
            width: 8px;
        }

        .chat-container::-webkit-scrollbar-track {
            background: #f1f1f1;
            border-radius: 10px;
        }

        .chat-container::-webkit-scrollbar-thumb {
            background: #888;
            border-radius: 10px;
        }

        .chat-container::-webkit-scrollbar-thumb:hover {
            background: #555;
        }

        /* Toggle button */
        .toggle-ui-btn {
            position: fixed;
            bottom: 20px;
            right: 20px;
            width: 60px;
            height: 60px;
            border-radius: 50%;
            background: rgba(102, 126, 234, 0.9);
            border: none;
            cursor: pointer;
            box-shadow: 0 4px 12px rgba(0, 0, 0, 0.3);
            z-index: 10;
            display: flex;
            align-items: center;
            justify-content: center;
            font-size: 24px;
            transition: all 0.3s ease;
        }

        .toggle-ui-btn:hover {
            background: rgba(102, 126, 234, 1);
            transform: scale(1.1);
            box-shadow: 0 6px 16px rgba(0, 0, 0, 0.4);
        }

        .toggle-ui-btn:active {
            transform: scale(0.95);
        }
    </style>
</head>
<body>
    <!-- Toggle UI Button -->
    <button class="toggle-ui-btn" id="toggleUIBtn" title="Toggle Voice Agent UI">üí¨</button>

    <div class="container">
        <h1>üéôÔ∏è Voice Agent</h1>
        <p class="subtitle">Talk to Eric, the pizza shop employee</p>

        <div class="instructions">
            <p>Press and hold <kbd>SPACE</kbd> to record, release to send</p>
        </div>

        <div class="status-indicator" id="status">
            <div class="status-dot"></div>
            <div class="status-text">Ready - Press Space to talk</div>
        </div>

        <div class="transcription-box" id="transcriptionBox">
            <div class="transcription-label">üé§ Live Transcription:</div>
            <div class="transcription-text" id="transcriptionText"></div>
        </div>

        <div class="chat-container" id="chatContainer">
            <!-- Messages will appear here -->
        </div>

        <div class="controls">
            <button class="btn btn-reset" onclick="resetConversation()">Reset Conversation</button>
        </div>

        <div class="error" id="error"></div>
    </div>

    <!-- 3D Background Canvas -->
    <div id="three-container">
        <canvas id="three-canvas"></canvas>
    </div>

    <script>
        let recognition;
        let isRecording = false;
        let isProcessing = false;
        let finalTranscript = '';
        let interimTranscript = '';

        // Initialize speech recognition
        function initSpeechRecognition() {
            if (!('webkitSpeechRecognition' in window) && !('SpeechRecognition' in window)) {
                showError('Speech recognition not supported in this browser. Please use Chrome.');
                return false;
            }

            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognition = new SpeechRecognition();
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'en-US';

            recognition.onstart = () => {
                console.log('Speech recognition started');
            };

            recognition.onresult = (event) => {
                interimTranscript = '';
                finalTranscript = '';

                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcript = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcript + ' ';
                    } else {
                        interimTranscript += transcript;
                    }
                }

                // Update the transcription display
                updateTranscription();
            };

            recognition.onerror = (event) => {
                console.error('Speech recognition error:', event.error);
                if (event.error !== 'no-speech' && event.error !== 'aborted') {
                    showError('Speech recognition error: ' + event.error);
                }
            };

            recognition.onend = () => {
                console.log('Speech recognition ended');
                if (isRecording) {
                    // Restart if we're still supposed to be recording
                    recognition.start();
                }
            };

            return true;
        }

        // Handle spacebar press and release
        document.addEventListener('keydown', async (e) => {
            if (e.code === 'Space' && !isRecording && !isProcessing) {
                e.preventDefault();
                await startRecording();
            }
        });

        document.addEventListener('keyup', async (e) => {
            if (e.code === 'Space' && isRecording) {
                e.preventDefault();
                await stopRecording();
            }
        });

        async function startRecording() {
            if (!recognition) {
                if (!initSpeechRecognition()) {
                    return;
                }
            }

            finalTranscript = '';
            interimTranscript = '';
            isRecording = true;

            // Show transcription box
            document.getElementById('transcriptionBox').classList.add('show');
            document.getElementById('transcriptionText').textContent = '';

            updateStatus('recording', 'Recording... Release Space to send');

            try {
                recognition.start();
            } catch (error) {
                console.error('Error starting recognition:', error);
                showError('Failed to start speech recognition');
                isRecording = false;
            }
        }

        async function stopRecording() {
            if (!recognition || !isRecording) {
                return;
            }

            isRecording = false;
            recognition.stop();

            // Get the final transcript
            const userText = (finalTranscript + interimTranscript).trim();

            if (!userText) {
                updateStatus('ready', 'Ready - Press Space to talk');
                document.getElementById('transcriptionBox').classList.remove('show');
                showError('No speech detected. Please try again.');
                return;
            }

            // Process the transcribed text
            await processTranscript(userText);
        }

        function updateTranscription() {
            const transcriptionText = document.getElementById('transcriptionText');
            const fullText = finalTranscript + interimTranscript;

            if (interimTranscript) {
                transcriptionText.innerHTML = finalTranscript + '<span class="interim">' + interimTranscript + '</span>';
            } else {
                transcriptionText.textContent = finalTranscript;
            }
        }

        async function processTranscript(userText) {
            isProcessing = true;
            updateStatus('processing', 'Processing...');

            // Hide transcription box
            document.getElementById('transcriptionBox').classList.remove('show');

            try {
                // Display user message
                addMessage('user', userText);

                // Step 1: Get chat response
                updateStatus('processing', 'Thinking...');
                const chatResponse = await fetch('/chat', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ text: userText })
                });

                if (!chatResponse.ok) {
                    throw new Error('Chat failed');
                }

                const chatData = await chatResponse.json();
                const assistantText = chatData.response;

                // Display assistant message
                addMessage('assistant', assistantText);

                // Step 2: Text to speech and auto-play
                updateStatus('processing', 'Speaking...');
                const ttsResponse = await fetch('/speak', {
                    method: 'POST',
                    headers: {
                        'Content-Type': 'application/json'
                    },
                    body: JSON.stringify({ text: assistantText })
                });

                if (!ttsResponse.ok) {
                    throw new Error('TTS failed');
                }

                const audioData = await ttsResponse.blob();
                const audioUrl = URL.createObjectURL(audioData);
                const audio = new Audio(audioUrl);

                // Auto-play the response
                await audio.play();

                // Wait for audio to finish playing
                audio.onended = () => {
                    isProcessing = false;
                    updateStatus('ready', 'Ready - Press Space to talk');
                };

            } catch (error) {
                console.error('Error:', error);
                showError(error.message);
                isProcessing = false;
                updateStatus('ready', 'Ready - Press Space to talk');
            }
        }

        function updateStatus(state, text) {
            const statusEl = document.getElementById('status');
            const statusText = statusEl.querySelector('.status-text');

            statusEl.className = 'status-indicator ' + state;
            statusText.textContent = text;
        }

        function addMessage(role, content) {
            const chatContainer = document.getElementById('chatContainer');
            const messageDiv = document.createElement('div');
            messageDiv.className = `message ${role}`;

            const label = role === 'user' ? 'You' : 'Eric';
            messageDiv.innerHTML = `
                <div class="message-label">${label}</div>
                <div class="message-content">${content}</div>
            `;

            chatContainer.appendChild(messageDiv);
            chatContainer.scrollTop = chatContainer.scrollHeight;
        }

        function showError(message) {
            const errorEl = document.getElementById('error');
            errorEl.textContent = message;
            errorEl.classList.add('show');

            setTimeout(() => {
                errorEl.classList.remove('show');
            }, 5000);
        }

        async function resetConversation() {
            try {
                await fetch('/reset', { method: 'POST' });
                document.getElementById('chatContainer').innerHTML = '';
                document.getElementById('transcriptionBox').classList.remove('show');
                finalTranscript = '';
                interimTranscript = '';
                updateStatus('ready', 'Ready - Press Space to talk');
            } catch (error) {
                showError('Failed to reset conversation');
            }
        }

        // Initialize on page load
        window.addEventListener('load', () => {
            updateStatus('ready', 'Ready - Press Space to talk');
            initSpeechRecognition();
        });

        // Toggle UI functionality
        const toggleUIBtn = document.getElementById('toggleUIBtn');
        const container = document.querySelector('.container');

        toggleUIBtn.addEventListener('click', () => {
            container.classList.toggle('hidden');
            // Update button icon based on state
            if (container.classList.contains('hidden')) {
                toggleUIBtn.textContent = 'üí¨';
                toggleUIBtn.title = 'Show Voice Agent UI';
            } else {
                toggleUIBtn.textContent = '‚úï';
                toggleUIBtn.title = 'Hide Voice Agent UI';
            }
        });
    </script>

    <!-- Three.js 3D Background Script -->
    <script type="module">
        import * as THREE from 'three';
        import { EffectComposer }  from 'three/addons/postprocessing/EffectComposer.js';
        import { RenderPass }      from 'three/addons/postprocessing/RenderPass.js';
        import { ShaderPass }      from 'three/addons/postprocessing/ShaderPass.js';
        import { SavePass }        from 'three/addons/postprocessing/SavePass.js';
        import { UnrealBloomPass } from 'three/addons/postprocessing/UnrealBloomPass.js';
        import { OutputPass }      from 'three/addons/postprocessing/OutputPass.js';
        import { GLTFLoader }      from 'https://unpkg.com/three@0.160.0/examples/jsm/loaders/GLTFLoader.js';
        import { DRACOLoader }     from 'https://unpkg.com/three@0.160.0/examples/jsm/loaders/DRACOLoader.js';
        import { OrbitControls }   from 'https://unpkg.com/three@0.160.0/examples/jsm/controls/OrbitControls.js';

        const canvas = document.getElementById('three-canvas');

        // ---------- Renderer ----------
        const renderer = new THREE.WebGLRenderer({ canvas, antialias: true, alpha: true });
        renderer.setPixelRatio(Math.min(window.devicePixelRatio, 2));
        // renderer.setSize(window.innerWidth, window.innerHeight);
        renderer.outputColorSpace = THREE.SRGBColorSpace;
        renderer.toneMapping = THREE.ACESFilmicToneMapping;
        // canvas.appendChild(renderer.domElement);

        // ---------- Scene / camera ----------
        const scene = new THREE.Scene();

        // ---------- Bloom exclusion list ----------
        // List object names to exclude from the bloom pass (they will still render in the final pass)
        // Edit this array to match names in your GLTF (e.g. ['Char', 'NoBloom'])
        const bloomExclude = ['Base001', 'Base'];

        // Internal storage for original visibility states when toggling bloom exclusion
        const _bloomHidden = [];
        function hideBloomExcluded(){
            _bloomHidden.length = 0;
            for (let name of bloomExclude){
                const obj = scene.getObjectByName(name);
                if (obj){
                    _bloomHidden.push({ obj, visible: obj.visible });
                    obj.visible = false;
                }
            }
        }
        function restoreBloomExcluded(){
            for (let rec of _bloomHidden) rec.obj.visible = rec.visible;
            _bloomHidden.length = 0;
        }

        // ---------- Background images ----------
        const bgPaths = [
            '/static/img/sky01.png',
            '/static/img/sky02.png',
            '/static/img/sky03.png',
            '/static/img/sky04.png'
        ];
        const texLoader = new THREE.TextureLoader();
        const bgTextures = bgPaths.map(p => texLoader.load(p));
        bgTextures.forEach(t => { try { if (t) t.colorSpace = THREE.SRGBColorSpace; } catch(e){} });

        let bgPass = null;
        function createBgPass(){
            // use the simple UV passthrough vertex shader already in the document
            const bgMat = new THREE.ShaderMaterial({
                uniforms: {
                    t0: { value: bgTextures[0] },
                    t1: { value: bgTextures[1] },
                    uMix: { value: 0.0 },
                    resolution: { value: new THREE.Vector2(window.innerWidth, window.innerHeight) }
                },
                vertexShader: `
                    varying vec2 vUv;
                    void main(){ vUv = uv; gl_Position = projectionMatrix * modelViewMatrix * vec4(position,1.0); }
                `,
                fragmentShader: `
                    varying vec2 vUv;
                    uniform sampler2D t0;
                    uniform sampler2D t1;
                    uniform float uMix;
                    void main(){
                        vec2 uv = vUv;
                        vec4 a = texture2D(t0, uv);
                        vec4 b = texture2D(t1, uv);
                        gl_FragColor = mix(a, b, uMix);
                    }
                `,
                depthWrite: false,
                depthTest: false,
                toneMapped: false
            });
            // create ShaderPass without a textureID so our t0/t1 uniforms are preserved
            bgPass = new ShaderPass(bgMat);
        }

        let bgIndex = 0;
        function setBackground(i){
            bgIndex = i % 10;
            // if we have a shader-driven bgPass, prefer it (we'll still update the label)
            if (bgPass && bgPass.material && bgPass.material.uniforms){
                updateBgFromIndex(bgIndex);
            }
        }
        setBackground(bgIndex);
        window.addEventListener('keydown', (e)=>{
            if (e.key === 'ArrowRight') setBackground(bgIndex + 1);
            if (e.key === 'ArrowLeft') setBackground(bgIndex - 1);
        });

        function updateBgFromIndex(index){
            const s = Number(index);
            const N = bgTextures.length;

            // sanity checks
            if (N === 0 || !bgPass || !bgPass.material || !bgPass.material.uniforms) return;

            const frac = (s / 10) * (N - 1);
            const i0 = Math.floor(frac);
            const i1 = Math.min(i0 + 1, N - 1);
            const localMix = frac - i0;

            // shader inputs
            bgPass.material.uniforms.t0.value = bgTextures[i0];
            bgPass.material.uniforms.t1.value = bgTextures[i1];
            bgPass.material.uniforms.uMix.value = localMix;
        }

        const camera = new THREE.PerspectiveCamera(50, window.innerWidth/window.innerHeight, 0.1, 100);
        camera.position.set(0.8, 0.8, 1.8);
        camera.lookAt(0, 0, 0);

        const controls = new OrbitControls(camera, renderer.domElement);
        controls.enableDamping = true;

        // ---------- GLB model ----------
        const loader = new GLTFLoader();
        const draco = new DRACOLoader();
        draco.setDecoderPath('https://unpkg.com/three@0.160.0/examples/jsm/libs/draco/');
        loader.setDRACOLoader(draco);

        let rockMesh = null;
        let charObj = null;
        let _charBaseY = 0;
        let _charBaseRotY = 0;

        function findCharInScene(){
            if (charObj) return charObj;
            const found = scene.getObjectByName('Char');
            if (found){
                charObj = found;
                _charBaseY = (charObj.position && typeof charObj.position.y === 'number') ? charObj.position.y : 0;
                _charBaseRotY = (charObj.rotation && typeof charObj.rotation.y === 'number') ? charObj.rotation.y : 0;
                charObj.matrixAutoUpdate = true;
                console.log('Found Char in scene, base Y =', _charBaseY);
            }
            return charObj;
        }

        function cheapNoise(t, seed=0){
            const s1 = Math.sin(t * 1.37 + seed * 12.34);
            const s2 = 0.6 * Math.sin(t * 2.73 + seed * 7.21);
            const s3 = 0.35 * Math.sin(t * 5.19 + seed * 3.11);
            return (s1 + s2 + s3) / (1.0 + 0.6 + 0.35);
        }

        function updateChar(t){
            if (!charObj) findCharInScene();
            if (!charObj) return;
            const seed = (charObj.id || 1) * 0.001;
            const freq = 0.1;
            const amp = 1;
            const n = cheapNoise(t * freq, seed);
            charObj.position.y = _charBaseY + n * amp;

            const rotFreq = 0.12;
            const maxAngle = Math.PI / 4;
            const nRot = cheapNoise(t * rotFreq, seed + 37.0);
            charObj.rotation.y = _charBaseRotY - Math.PI + nRot * maxAngle;
        }

        const rockMat = new THREE.ShaderMaterial({
            uniforms: {
                uTime:      { value: 0 },
                uColorA:    { value: new THREE.Color(0x736c61) },
                uColorB:    { value: new THREE.Color(0x94a18c) },
                uGlow:      { value: 1.3 },
                uHueOffset: { value: 0.0 },
                uHueScale:  { value: 1.0 },
                uHueSpeed:  { value: 0.3 },
                uHueSat:    { value: 0.5 },
                uEdgeStrength: { value: 0.9 },
                // Blob effect
                uAmp: {value: 0.5},
                uFreq: {value: 0.3 },
                uSpeed: {value: 0.4}
            },
            vertexShader: `
                varying vec3 vPos;
                varying vec3 vNormal;
                varying vec3 viewDir;

                uniform float uTime;      // seconds
                uniform float uAmp;       // displacement amplitude
                uniform float uFreq;      // spatial frequency
                uniform float uSpeed;     // time scale

                // cheap value-noise (hash + trilinear)
                float hash(vec3 p){
                    return fract(sin(dot(p, vec3(127.1,311.7, 74.7))) * 43758.5453);
                }

                float noise(vec3 x){
                    vec3 i = floor(x), f = fract(x);
                    float n000=hash(i+vec3(0,0,0)), n100=hash(i+vec3(1,0,0));
                    float n010=hash(i+vec3(0,1,0)), n110=hash(i+vec3(1,1,0));
                    float n001=hash(i+vec3(0,0,1)), n101=hash(i+vec3(1,0,1));
                    float n011=hash(i+vec3(0,1,1)), n111=hash(i+vec3(1,1,1));
                    vec3 u = f*f*(3.0-2.0*f);
                    float nx00 = mix(n000,n100,u.x), nx10 = mix(n010,n110,u.x);
                    float nx01 = mix(n001,n101,u.x), nx11 = mix(n011,n111,u.x);
                    float nxy0 = mix(nx00,nx10,u.y), nxy1 = mix(nx01,nx11,u.y);

                    return mix(nxy0,nxy1,u.z);
                }

                void main(){
                    vPos = position * 3.0;
                    vNormal = normalize( normalMatrix * normal );
                    vec4 mvPos = modelViewMatrix * vec4(position, 1.0);
                    viewDir = normalize( -mvPos.xyz );

                    vec3 pos = position;
                    float mask = 1.0 - ((dot(vNormal, viewDir) + 1.0) * 0.5);
                    float n = noise(position * uFreq + vec3(0.0, 0.0, uTime * uSpeed));
                    float disp = (n * 2.0 - 1.0) * uAmp * mask;
                    pos += normalize(normal) * disp;

                    gl_Position = projectionMatrix * modelViewMatrix * vec4(pos, 1.0);
                }
            `,
            fragmentShader: `
                varying vec3 vPos;
                varying vec3 vNormal;
                varying vec3 viewDir;
                uniform float uTime;
                uniform vec3  uColorA, uColorB;
                uniform float uGlow;
                uniform float uHueOffset;
                uniform float uHueScale;
                uniform float uEdgeStrength;
                uniform float uHueSat;
                uniform float uHueSpeed;

                vec3 hsv2rgb(float h, float s, float v){
                    vec3 p = abs(fract(h + vec3(0.0, 2.0/3.0, 1.0/3.0)) * 6.0 - 3.0);
                    vec3 rgb = clamp(p - 1.0, 0.0, 1.0);
                    return mix(vec3(1.0), rgb, s) * v;
                }

                void main(){
                    vec3 N = normalize(vNormal);
                    float bands = abs( sin(vPos.x) * sin(vPos.y) * sin(vPos.z) );
                    float mask = smoothstep(0.2, 0.8, bands);
                    vec3 base = mix(uColorA, uColorB, mask);
                    float pulse = 0.5 + 0.5 * sin(uTime * 2.0);
                    vec3 tint = vec3(
                        1.0 + 0.06 * cos(uTime * 1.7),
                        1.0 + 0.06 * cos(uTime * 1.1 + 1.57),
                        1.0 + 0.06 * cos(uTime * 1.3 + 3.14)
                    );
                    vec3 color = base * tint;
                    color += uGlow * pulse * vec3(0.6);

                    float ndotv = dot(N, normalize(viewDir));
                    float edge = pow(1.0 - clamp(ndotv, -1.0, 1.0), 2.0);

                    float angle = atan(vPos.y, vPos.x);
                    float hue = (angle / (6.28318530718)) + 0.5;
                    hue = mod(hue + uHueOffset, 1.0);

                    vec3 radialHue = hsv2rgb(hue, uHueSat, 1.0);
                    color = radialHue * edge;
                    gl_FragColor = vec4(color, 1.0);
                }
            `
        });

        loader.load('/static/models/rock.glb', (gltf) => {
            const root = gltf.scene;

            const box = new THREE.Box3().setFromObject(root);
            const size = new THREE.Vector3(); box.getSize(size);
            const center = new THREE.Vector3(); box.getCenter(center);
            root.position.sub(center);
            const s = 1 / Math.max(size.x, size.y, size.z || 1e-6);
            root.scale.setScalar(s);

            root.traverse(o => {
                console.log(o.name);
                if (!rockMesh && o.isMesh && o.name == "Rock") rockMesh = o;
            });
            if (rockMesh) rockMesh.material = rockMat;

            scene.add(root);
        }, undefined, err => console.error('GLB load error:', err));

        scene.add(new THREE.HemisphereLight(0xffffff, 0x334455, 1.0));

        const light = new THREE.DirectionalLight(0xffffff, 1);
        light.position.set(2, 3, 2);
        scene.add(light);

        // Reusable render pass for both composers
        const renderScene = new RenderPass(scene, camera);
        renderScene.clear = true;
        renderScene.clearAlpha = 0.0;

        const renderTarget = new THREE.WebGLRenderTarget(100, 100, {
            depthBuffer: false, stencilBuffer: false
        });

        // ---------- Bloom composer (off-screen) ----------
        const bloomComposer = new EffectComposer(renderer);
        bloomComposer.renderToScreen = false;
        const bloomPass = new UnrealBloomPass(
            new THREE.Vector2(window.innerWidth, window.innerHeight),
            2.4,
            1.0,
            0.1
        );

        if (!bgPass) createBgPass();
        bloomComposer.addPass(bgPass);
        bloomComposer.addPass(renderScene);
        bloomComposer.addPass(bloomPass);
        bloomComposer.addPass(new SavePass(renderTarget));

        // ---------- Final composer ----------
        const finalComposer = new EffectComposer(renderer);

        scene.background = null;

        if (!bgPass) createBgPass();
        finalComposer.addPass(bgPass);

        const renderSceneFinal = new RenderPass(scene, camera);
        renderSceneFinal.clear = false;
        renderSceneFinal.clearAlpha = 0.0;
        finalComposer.addPass(renderSceneFinal);

        const mixPass = new ShaderPass(
            new THREE.ShaderMaterial({
                uniforms: {
                    baseTexture:  { value: renderTarget },
                    bloomTexture: { value: bloomComposer.renderTarget2.texture }
                },
                vertexShader: `
                    varying vec2 vUv;
                    void main(){ vUv = uv; gl_Position = projectionMatrix * modelViewMatrix * vec4(position,1.0); }
                `,
                fragmentShader: `
                    uniform sampler2D baseTexture;
                    uniform sampler2D bloomTexture;
                    varying vec2 vUv;
                    void main(){
                        vec4 base  = texture2D(baseTexture,  vUv);
                        vec4 bloom = texture2D(bloomTexture, vUv);
                        gl_FragColor = vec4(base.rgb + 0.5*bloom.rgb, 1.0);
                    }
                `
            }),
            'baseTexture'
        );
        mixPass.needsSwap = true;
        finalComposer.addPass(mixPass);
        finalComposer.addPass(new OutputPass());

        // ---------- Resize ----------
        function onResize(){
            const container = document.getElementById('three-container');
            const w = container.clientWidth, h = container.clientHeight;
            console.log(w, h);
            renderer.setSize(w, h);
            renderTarget.setSize(w,h);
            camera.aspect = w/h;
            camera.updateProjectionMatrix();
            bloomComposer.setSize(w, h);
            finalComposer.setSize(w, h);
            bloomPass.setSize(w, h);
        }
        addEventListener('resize', onResize);
        onResize();

        // ---------- Animation Loop ----------
        const clock = new THREE.Clock();
        renderer.setAnimationLoop(() => {
            controls.update();
            const t = clock.getElapsedTime();

            rockMat.uniforms.uTime.value = t;
            rockMat.uniforms.uHueOffset.value = t * rockMat.uniforms.uHueSpeed.value % 1.0;

            try { updateChar(t); } catch(e) {}

            try{ hideBloomExcluded(); } catch(e){}
            bloomComposer.render();
            try{ restoreBloomExcluded(); } catch(e){}

            finalComposer.render();
        });
    </script>
</body>
</html>
