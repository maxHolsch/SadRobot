<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>Chat Bot Interaction</title>
<link rel="stylesheet" href="css/survey.css">
<link rel="stylesheet" href="css/instructions.css">
<link rel="stylesheet" href="css/main.css">
<link rel="preconnect" href="https://fonts.googleapis.com">
<link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
<link href="https://fonts.googleapis.com/css2?family=Inter:wght@400;500;600;700&display=swap" rel="stylesheet">
</head>
<body>

<!-- Survey Container -->
<div id="survey-container"></div>

<!-- Instructions Container -->
<div id="instructions-container"></div>

<!-- Main Content (hidden until survey is completed) -->
<div id="main-content">
<div id="stage">
  <div id="backdrop"></div>
  <video id="v0" playsinline muted preload="auto" loop crossorigin="anonymous"></video>
  <video id="v1" playsinline muted preload="auto" loop crossorigin="anonymous"></video>
  <div id="blackBox"></div>
</div>

<div id="controls">
  <div id="voiceStatus">  </div>
  <button id="endInteractionBtn">â†’ End chat and go to survey</button>
</div>
</div> <!-- End main-content -->

<script type="module">
// Import dependencies
import { Conversation } from 'https://cdn.jsdelivr.net/npm/@11labs/client/+esm';
import { VideoMixer, intro_video, idle_video, preloadAllVideos } from './js/videoMixer.js';
import EmotionAnalyzer from './js/emotionAnalyzer.js';
import './js/emotionDebug.js'; // Debug utilities
import './js/survey.js';
import { initializeInstructions } from './js/instructions.js';

// Make initializeInstructions globally available
window.initializeInstructions = initializeInstructions;

// Robot tag to identify which version of the robot (sad/happy) this session is using
// Change this to "happy" for the control group branch
// This should match the ROBOT_TAG in survey.js
const ROBOT_TAG = 'sad';

// Make sure all videos are preloaded for when they're needed.
preloadAllVideos();

// Helper function to reset survey (for testing)
// Usage in console: resetSurvey()
window.resetSurvey = function() {
  localStorage.removeItem('consentCompleted');
  localStorage.removeItem('consentData');
  localStorage.removeItem('surveyCompleted');
  localStorage.removeItem('surveyCompletionTime');
  location.reload();
};

// UI Helper
// Update status message
function setStatus(message, type = "info") {
  voiceStatus.textContent = message;
  voiceStatus.className = type;
}

// === SKIP SURVEY MODE (set to true to bypass consent/survey) ===
const SKIP_SURVEY = false;
// ================================================================

// Check if consent and survey are already completed on page load
if (SKIP_SURVEY || (localStorage.getItem('consentCompleted') === 'true' && localStorage.getItem('surveyCompleted') === 'true')) {
  // Hide survey container
  const surveyContainer = document.getElementById('survey-container');
  if (surveyContainer) {
    surveyContainer.style.display = 'none';
  }
  
  // Always show instructions page before main content
  initializeInstructions();
}

// Initialize video mixer and emotion analyzer only when main content is shown
let videoMixer = null;
let emotionAnalyzer = null;
let videoMixerInitialized = false;

function initializeVideoMixer() {
  if (videoMixerInitialized) return;

  const stage = document.getElementById('stage');
  if (!stage) return;

  videoMixer = new VideoMixer(stage);
  window.videoMixer = videoMixer; // Make available globally for other modules

  // Initialize emotion analyzer
  emotionAnalyzer = new EmotionAnalyzer();
  window.emotionAnalyzer = emotionAnalyzer; // Make available globally

  videoMixerInitialized = true;

  console.log('[Main] Video mixer and emotion analyzer initialized');
}

// Callback for when instructions are complete
window.onInstructionsComplete = function() {
  setStatus("Waking up...", "info");

  initializeVideoMixer();
  // Auto-start voice conversation
    if (window.startVoiceConversation) {
      window.startVoiceConversation();
    }
};

// --- Voice Agent Integration ---
(() => {
  const voiceStatus = document.getElementById("voiceStatus");
  let conversation = null;
  let isConnected = false;
  let isIdle = true;

  // Initialize ElevenLabs conversation
  async function initializeVoiceAgent() {
    try {

      // Get signed URL from our backend
      const response = await fetch("/api/get-signed-url");
      if (!response.ok) {
        throw new Error("Failed to get signed URL");
      }

      const { signedUrl, conversationId: backendConversationId } = await response.json();
      console.log("Backend provided conversation ID:", backendConversationId);

      // Initialize ElevenLabs conversation using the imported Conversation class
      conversation = await Conversation.startSession({
        signedUrl: signedUrl,
        onConnect: async () => {
          console.log("Voice agent connected");
          isConnected = true;
          window.conversation = conversation; // Expose globally for end interaction button

          setStatus("âœ” Listening. Speak when you're ready.", "info");

          // Capture and store the conversation ID after connection
          // Use setTimeout to ensure conversation object is fully initialized
          setTimeout(async () => {
            // Debug: Log all properties of the conversation object
            console.log("Conversation object keys:", Object.keys(conversation));
            console.log("Full conversation object:", conversation);

            // Check connection object
            if (conversation.connection) {
              console.log("Connection object keys:", Object.keys(conversation.connection));
              console.log("Connection object:", conversation.connection);
            }

            // Check options object (might contain conversation metadata)
            if (conversation.options) {
              console.log("Options object:", conversation.options);
            }

            // Try to extract conversation ID from multiple sources
            let conversationId = null;

            // Method 0: Use conversation ID from backend if available
            if (backendConversationId) {
              conversationId = backendConversationId;
              console.log("Using conversation ID from backend:", conversationId);
            }

            // Method 1: Check conversation object properties
            if (!conversationId) {
              conversationId =
                conversation.conversationId ||
                conversation.id ||
                conversation._id ||
                conversation.conversation_id ||
                conversation.sessionId ||
                conversation.session_id ||
                null;
            }

            // Method 2: Check connection object
            if (!conversationId && conversation.connection) {
              conversationId =
                conversation.connection.conversationId ||
                conversation.connection.id ||
                conversation.connection.conversation_id ||
                conversation.connection.agentId ||
                null;
            }

            // Method 3: Extract from signed URL (if available in options)
            if (!conversationId && conversation.options && conversation.options.signedUrl) {
              try {
                const url = new URL(conversation.options.signedUrl);
                conversationId = url.searchParams.get('conversation_id') ||
                                url.searchParams.get('conversationId') ||
                                url.pathname.split('/').pop() || // Last part of path
                                null;
                console.log("Attempting to extract from URL:", url.href);
              } catch (e) {
                console.log("Could not parse signed URL");
              }
            }

            console.log("Final extracted Conversation ID:", conversationId);

            if (conversationId) {
              // Get or create session ID
              let sessionId = localStorage.getItem('userSessionId');
              if (!sessionId) {
                sessionId = `session_${Date.now()}_${Math.random().toString(36).substr(2, 9)}`;
                localStorage.setItem('userSessionId', sessionId);
              }

              // Store conversation ID in Supabase
              try {
                const response = await fetch('/api/update-conversation-id', {
                  method: 'POST',
                  headers: {
                    'Content-Type': 'application/json',
                  },
                  body: JSON.stringify({ sessionId, conversationId, robotTag: ROBOT_TAG }),
                });

                const result = await response.json();

                if (response.ok) {
                  console.log('âœ… Conversation ID stored successfully:', result);
                } else {
                  console.error('âŒ Failed to store conversation ID:', result);
                }
              } catch (error) {
                console.error('âŒ Error storing conversation ID:', error);
              }
            } else {
              console.warn('âš ï¸ No conversation ID found in Conversation object');
              console.warn('Available properties:', Object.keys(conversation));
              console.warn('ðŸ’¡ You may need to retrieve the conversation ID from the ElevenLabs API after the conversation ends');
            }
          }, 500);
        },
        onDisconnect: () => {
          console.log("Voice agent disconnected");
          isConnected = false;
          window.conversation = null; // Clear global reference
          setStatus("", "info");
          conversation = null;
        },
        onError: (error) => {
          console.error("Voice agent error:", error);
          setStatus("Connection error. Please refresh the page.", "error");
          isConnected = false;
          window.conversation = null; // Clear global reference
          conversation = null;
        },
        onMessage: (message) => {
          console.log("Agent message:", message);

          if(isIdle) {
            videoMixer.setTalking(true);
            isIdle = false;
          }

          // Only analyze robot's responses (AI messages), not user messages
          if (message && message.source === 'ai' && message.message && window.emotionAnalyzer) {
            const text = message.message;
            window.emotionAnalyzer.storeMessage(text);
          }
        },
        onModeChange: (change) => {

          if(isIdle) {
            return; // Ignore initial mode changes before first message
          }

          if(change.mode === 'listening') {

            if(videoMixer.currentIndex() == 1) { // Marvin is getting better
              setStatus("What you're doing is working. Keep going.", "info");
            }

            if(videoMixer.currentIndex() == 2) { // Marvin is sufficiently cheered up
              setStatus("You've cheered Marvin up! Click the 'End chat' button to move on, or keep chatting if you enjoy the conversation.", "info");
              
              // Change button appearance to indicate completion
              const endBtn = document.getElementById('endInteractionBtn');
              if (endBtn) {
                endBtn.style.background = 'white';
                endBtn.style.color = 'black';
              }
            }

            videoMixer.setTalking(false);

            // While the user speaks, we analyze the ai emotion and do a potential switch
            console.log('-- Affect:', emotionAnalyzer.currentAffect);
            var affect  = emotionAnalyzer.currentAffect;
            var mappedIndex = Math.min(2, Math.round(affect));

            if(mappedIndex > videoMixer.currentIndex()){
              videoMixer.queueNewCurrentIndex(mappedIndex);
            }

          } else if(change.mode === 'speaking') {
            videoMixer.setTalking(true);
          } else {
            console.log("Unknown conversation mode: " + change.mode, "error");
          }
        }
      });
    } catch (error) {
      console.error("Failed to initialize voice agent:", error);
      setStatus(`Failed to connect: ${error.message}`, "error");
      isConnected = false;
      conversation = null;
    }
  }

  // End conversation
  async function endConversation() {
    if (conversation) {
      try {
        await conversation.endSession();
        conversation = null;
        window.conversation = null; // Clear global reference
        isConnected = false;
        setStatus("", "info");
        
        // Hide all videos
        if (videoMixer && videoMixer.vids) {
          videoMixer.vids.forEach(vid => {
            try {
              vid.pause();
              vid.classList.remove('active', 'on-top');
            } catch (e) {
              console.warn('Error hiding video:', e);
            }
          });
        }
      } catch (error) {
        console.error("Error ending conversation:", error);
      }
    }
  }
  
  // Expose functions globally
  window.endVoiceConversation = endConversation;
  
  // Function to start voice conversation (called automatically after instructions)
  window.startVoiceConversation = async function() {
    if (isConnected) {
      return;
    }

    try {
      setTimeout(() => {
        console.log('Starting voice agent initialization during intro video...');
        initializeVoiceAgent().catch((err) => {
          console.error('initializeVoiceAgent failed:', err);
        });
      }, 500);

      // Play intro video, then immediately transition to looping idle video
      videoMixer.playIntroThenIdle(intro_video, idle_video).catch((e) => { 
        console.warn('playIntroThenIdle failed', e); 
      });
      console.log(`[${new Date().toISOString()}] Intro->Idle sequence started.`);

    } catch (err) {
      console.error('Error during conversation start:', err);
      setStatus('Error starting conversation', 'error');
    }
  };

  // Cleanup on page unload
  window.addEventListener("beforeunload", () => {
    if (conversation) {
      conversation.endSession();
    }
  });
})();

// End Interaction button - triggers post-study survey
const endInteractionBtn = document.querySelector("#endInteractionBtn");
endInteractionBtn.onclick = async () => {
  // Confirm before ending interaction
  if (confirm('Are you sure you want to end the interaction? You will be asked to complete a post-study survey.')) {
    // End voice conversation if active
    if (window.endVoiceConversation) {
      await window.endVoiceConversation();
    }

    // Submit final affect score to backend
    if (window.emotionAnalyzer) {
      try {
        const finalAffect = window.emotionAnalyzer.currentAffect;
        const sessionId = localStorage.getItem('userSessionId');
        await fetch('/api/submit-affect', {
          method: 'POST',
          headers: { 'Content-Type': 'application/json' },
          body: JSON.stringify({ sessionId, finalAffect, timestamp: new Date().toISOString() })
        });
      } catch (err) {
        console.error('Failed to submit final affect score:', err);
        // Continue to post-survey regardless
      }
    }

    // Start post-survey
    if (window.startPostSurvey) {
      window.startPostSurvey();
    }
  }
};
</script>
</body>
</html>