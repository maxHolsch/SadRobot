<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>Video Crossfade with Slider (4 clips)</title>
<link rel="stylesheet" href="css/survey.css">
<style>
  html, body {
    background: black;
    /* keep room for fixed controls so they don't overlap the page content */
    padding-bottom: 88px;
  }
  /* Full-bleed backdrop behind the stage that fills the viewport width */
  #backdrop {
    position: fixed;
    left: 0;
    top: 0;
    width: 100vw;
    height: calc(100vh - 88px); /* leave room for controls */
    background-image: url('backdrop.png');
    background-size: cover;
    background-position: center center;
    background-repeat: no-repeat;
    z-index: 0;
    pointer-events: none;
  }
  #stage { 
    position: relative; 
    width: 100%; 
    max-width: 960px; 
    aspect-ratio: 16/9; 
    background: transparent; /* allow backdrop to show through for blending */
    z-index: 10; /* sit above backdrop but below controls */
    margin: 0 auto;
    /* Add top margin to push stage down */
    margin-top: calc((100vh - 88px - (960px * 9/16)) / 2);
  }
  #stage video {
    position: absolute; inset: 0; width: 100%; height: 100%;
    object-fit: cover; opacity: 0; pointer-events: none; z-index: 1;
    /* Blend video with backdrop using screen for better black handling */
    mix-blend-mode: screen;
    transition: opacity 300ms linear;
  }
  #stage video.active { opacity: 1; }
  #stage video.on-top { z-index: 2; }

  /* Black box overlay in bottom right corner */
  #blackBox {
    position: absolute;
    bottom: 0;
    right: 0;
    width: 20%;
    height: 20%;
    background: #000;
    z-index: 10;
    pointer-events: none;
  }

  /* Fullscreen styles */
  #stage:fullscreen {
    max-width: 100%;
    width: 100vw;
    height: 100vh;
    margin: 0;
  }
  #stage:-webkit-full-screen {
    max-width: 100%;
    width: 100vw;
    height: 100vh;
    margin: 0;
  }
  #stage:-moz-full-screen {
    max-width: 100%;
    width: 100vw;
    height: 100vh;
    margin: 0;
  }
  /* Controls are fixed to the bottom of the viewport (floating bar) */
  #controls {
    position: fixed;
    left: 0;
    right: 0;
    bottom: 0;
    display: flex;
    gap: .75rem;
    align-items: center;
    justify-content: center;
    padding: 10px 14px;
    background: rgba(0,0,0,0.55);
    backdrop-filter: blur(6px);
    z-index: 50;
    flex-wrap: wrap;
    font: 14px/1.4 system-ui, sans-serif;
    color: #ddd;
  }
  button { padding:.45rem .8rem; border:1px solid #444; background:#111; color:#eee; border-radius:.5rem; cursor:pointer; }
  button:hover { background:#222; }
  input[type="range"] { width: 260px; }
  .val { min-width: 1.5ch; text-align: right; display:inline-block; }

  /* Voice Agent Button */
  #voiceAgentBtn {
    padding: 0.6rem 1.2rem;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    border: 2px solid #8b5cf6;
    color: white;
    font-weight: 600;
    font-size: 15px;
    transition: all 0.3s ease;
    position: relative;
    overflow: hidden;
  }
  #voiceAgentBtn:hover {
    background: linear-gradient(135deg, #764ba2 0%, #667eea 100%);
    transform: translateY(-2px);
    box-shadow: 0 4px 12px rgba(139, 92, 246, 0.4);
  }
  #voiceAgentBtn.active {
    background: linear-gradient(135deg, #ef4444 0%, #dc2626 100%);
    border-color: #ef4444;
    animation: pulse 1.5s infinite;
  }
  #voiceAgentBtn.connected {
    background: linear-gradient(135deg, #10b981 0%, #059669 100%);
    border-color: #10b981;
  }
  @keyframes pulse {
    0%, 100% { opacity: 1; }
    50% { opacity: 0.7; }
  }

  /* Voice Agent Status */
  #voiceStatus {
    font-size: 12px;
    color: #888;
    margin-top: 8px;
    text-align: center;
  }
  #voiceStatus.active { color: #10b981; }
  #voiceStatus.error { color: #ef4444; }
</style>
</head>
<body>

<!-- Survey Container -->
<div id="survey-container"></div>

<!-- Main Content (hidden until survey is completed) -->
<div id="main-content">
<div id="stage">
  <div id="backdrop"></div>
  <video id="v0" playsinline muted preload="auto" loop crossorigin="anonymous"></video>
  <video id="v1" playsinline muted preload="auto" loop crossorigin="anonymous"></video>
  <div id="blackBox"></div>
</div>

<div id="controls">
  <button id="voiceAgentBtn">ðŸŽ¤ Talk to Sad Robot</button>
  <button id="endInteractionBtn" style="background: linear-gradient(135deg, #ef4444 0%, #dc2626 100%); border-color: #ef4444; font-weight: 600;">End Interaction</button>
  <div id="voiceStatus">  </div>
</div>
</div> <!-- End main-content -->

<script type="module">
// Import dependencies
import { Conversation } from 'https://cdn.jsdelivr.net/npm/@11labs/client/+esm';
import { VideoMixer, intro_video } from './js/videoMixer.js';
import './js/survey.js';

// Helper function to reset survey (for testing)
// Usage in console: resetSurvey()
window.resetSurvey = function() {
  localStorage.removeItem('surveyCompleted');
  localStorage.removeItem('surveyCompletionTime');
  location.reload();
};

// Initialize video mixer only when main content is shown
let videoMixer = null;
let videoMixerInitialized = false;

function initializeVideoMixer() {
  if (videoMixerInitialized) return;
  
  const stage = document.getElementById('stage');
  if (!stage) return;
  
  videoMixer = new VideoMixer(stage);
  window.videoMixer = videoMixer; // Make available globally for other modules

  // Initialize but don't autoplay
  videoMixer.initPlaylistBuffers();
  videoMixerInitialized = true;
}

// Initialize video mixer when survey is completed or if already completed
window.addEventListener('surveyCompleted', () => {
  initializeVideoMixer();
});

// Check if survey is already completed on page load
if (localStorage.getItem('surveyCompleted') === 'true') {
  // Survey already completed, show main content and initialize video mixer
  const mainContent = document.getElementById('main-content');
  if (mainContent) {
    mainContent.style.display = 'block';
  }
  const surveyContainer = document.getElementById('survey-container');
  if (surveyContainer) {
    surveyContainer.style.display = 'none';
  }
  // Initialize video mixer after a short delay to ensure DOM is ready
  setTimeout(() => {
    initializeVideoMixer();
  }, 100);
}

// --- Voice Agent Integration ---
(() => {
  const voiceBtn = document.getElementById("voiceAgentBtn");
  const voiceStatus = document.getElementById("voiceStatus");
  let conversation = null;
  let isConnected = false;

  // Update status message
  function setStatus(message, type = "info") {
    voiceStatus.textContent = message;
    voiceStatus.className = type;
  }

  // Initialize ElevenLabs conversation
  async function initializeVoiceAgent() {
    try {
      setStatus("Connecting to Sad Robot...", "info");
      voiceBtn.classList.add("active");
      voiceBtn.disabled = true;

      // Get signed URL from our backend
      const response = await fetch("/api/get-signed-url");
      if (!response.ok) {
        throw new Error("Failed to get signed URL");
      }

      const { signedUrl } = await response.json();

      setStatus("Starting conversation...", "info");

      // Initialize ElevenLabs conversation using the imported Conversation class
      conversation = await Conversation.startSession({
        signedUrl: signedUrl,
        onConnect: () => {
          console.log("Voice agent connected");
          isConnected = true;
          window.conversation = conversation; // Expose globally for end interaction button
          voiceBtn.classList.remove("active");
          voiceBtn.classList.add("connected");
          voiceBtn.textContent = "ðŸ”´ End Conversation";
          voiceBtn.disabled = false;
          setStatus("Connected! Start talking to the Sad Robot", "active");
        },
        onDisconnect: () => {
          console.log("Voice agent disconnected");
          isConnected = false;
          window.conversation = null; // Clear global reference
          voiceBtn.classList.remove("active", "connected");
          voiceBtn.textContent = "ðŸŽ¤ Talk to Sad Robot";
          voiceBtn.disabled = false;
          setStatus("", "info");
          conversation = null;
        },
        onError: (error) => {
          console.error("Voice agent error:", error);
          setStatus("Connection error. Please try again.", "error");
          voiceBtn.classList.remove("active", "connected");
          voiceBtn.textContent = "ðŸŽ¤ Talk to Sad Robot";
          voiceBtn.disabled = false;
          isConnected = false;
          window.conversation = null; // Clear global reference
          conversation = null;
        },
        onMessage: (message) => {
          console.log("Agent message:", message);
          videoMixer.handleMessage(message);

          // Store conversation text for analysis at next video loop
          if (message && message.message && window.emotionAnalyzer) {
            const text = message.message;
            window.emotionAnalyzer.storeMessage(text);
          }
        },
      });
    } catch (error) {
      console.error("Failed to initialize voice agent:", error);
      setStatus(`Failed to connect: ${error.message}`, "error");
      voiceBtn.classList.remove("active", "connected");
      voiceBtn.textContent = "ðŸŽ¤ Talk to Sad Robot";
      voiceBtn.disabled = false;
      isConnected = false;
      conversation = null;
    }
  }

  // End conversation
  async function endConversation() {
    if (conversation) {
      try {
        await conversation.endSession();
        conversation = null;
        window.conversation = null; // Clear global reference
        isConnected = false;
        voiceBtn.classList.remove("active", "connected");
        voiceBtn.textContent = "ðŸŽ¤ Talk to Sad Robot";
        setStatus("", "info");
      } catch (error) {
        console.error("Error ending conversation:", error);
      }
    }
  }
  
  // Expose endConversation globally for end interaction button
  window.endVoiceConversation = endConversation;

  // Start button click handler
  voiceBtn.addEventListener("click", async () => {
    if (isConnected) {
      await endConversation();
      return;
    }

    // Prevent double clicks
    voiceBtn.disabled = true;
    voiceBtn.classList.add('active');
    setStatus('Preparing...', 'info');

    try {
      // Initialize voice agent after a 5 second delay; do NOT await so the UI flow isn't blocked by the voice init.
      setTimeout(() => {
        console.log('Starting voice agent initialization during intro video...');
        initializeVoiceAgent().catch((err) => {
          console.error('initializeVoiceAgent failed:', err);
        });
      }, 5000);

      // Play the intro one-shot video first. After it finishes, start the playlist.
      setStatus('Playing intro video...', 'info');
      await videoMixer.playOneShot(intro_video).catch((e) => { console.warn('playOneShot failed', e); });

      // Start the usual playlist mechanism
      try { videoMixer.beginPlaylist(); } catch (e) { console.warn('beginPlaylist failed', e); }

    } catch (err) {
      console.error('Error during talk-button flow:', err);
      setStatus('Error starting conversation', 'error');
    } finally {
      voiceBtn.disabled = false;
      voiceBtn.classList.remove('active');
    }
  });

  // Cleanup on page unload
  window.addEventListener("beforeunload", () => {
    if (conversation) {
      conversation.endSession();
    }
  });
})();

// --- Audio Playback Monitor ---
(() => {
  let audioIsPlaying = false;
  let currentPlayingAudio = null;

  // Track all audio elements on the page
  function monitorAudioElement(audioElement) {
    audioElement.addEventListener('play', () => {
      audioIsPlaying = true;
      currentPlayingAudio = audioElement;
      console.log('ðŸ”Š Audio started playing');

      // Call custom callback if defined
      if (window.onAudioPlaybackChange) {
        window.onAudioPlaybackChange(true);
      }
    });

    audioElement.addEventListener('pause', () => {
      audioIsPlaying = false;
      currentPlayingAudio = null;
      console.log('ðŸ”‡ Audio paused');

      if (window.onAudioPlaybackChange) {
        window.onAudioPlaybackChange(false);
      }
    });

    audioElement.addEventListener('ended', () => {
      audioIsPlaying = false;
      currentPlayingAudio = null;
      console.log('âœ“ Audio ended');

      if (window.onAudioPlaybackChange) {
        window.onAudioPlaybackChange(false);
      }
    });
  }

  // Monitor existing audio elements
  document.querySelectorAll('audio').forEach(monitorAudioElement);

  // Watch for dynamically created audio elements (like from ElevenLabs)
  const observer = new MutationObserver((mutations) => {
    mutations.forEach((mutation) => {
      mutation.addedNodes.forEach((node) => {
        // Debug: log all node types being added
        console.log('ðŸ” Node added:', node.nodeName, node);

        if (node.tagName === 'AUDIO') {
          console.log('ðŸŽµ New audio element detected');
          monitorAudioElement(node);
        }
        // Also check child nodes
        if (node.querySelectorAll) {
          const audioElements = node.querySelectorAll('audio');
          if (audioElements.length > 0) {
            console.log('ðŸŽµ Found', audioElements.length, 'audio elements in child nodes');
            audioElements.forEach(monitorAudioElement);
          }
        }
      });
    });
  });

  // Start observing the document for audio elements
  observer.observe(document.body, {
    childList: true,
    subtree: true
  });

  // Periodically check for audio elements (in case they're in shadow DOM)
  setInterval(() => {
    const allAudio = document.querySelectorAll('audio');
    console.log('ðŸ” Periodic check: found', allAudio.length, 'audio elements');
    allAudio.forEach(audio => {
      if (!audio.dataset.monitored) {
        console.log('ðŸŽµ Found unmonitored audio element!');
        audio.dataset.monitored = 'true';
        monitorAudioElement(audio);
      }
    });
  }, 2000);

  // Public API
  window.audioMonitor = {
    isPlaying: () => audioIsPlaying,
    getCurrentAudio: () => currentPlayingAudio,
  };

  console.log('[Audio Monitor] Initialized - tracking all audio playback');
})();

// --- UI wiring ---
const $ = (s) => document.querySelector(s);

// Fullscreen toggle
const fullscreenBtn = $("#fullscreenBtn");

/*
fullscreenBtn.onclick = () => {
  if (!document.fullscreenElement && !document.webkitFullscreenElement && !document.mozFullScreenElement) {
    if (stage.requestFullscreen) {
      stage.requestFullscreen();
    } else if (stage.webkitRequestFullscreen) {
      stage.webkitRequestFullscreen();
    } else if (stage.mozRequestFullScreen) {
      stage.mozRequestFullScreen();
    }
  } else {
    if (document.exitFullscreen) {
      document.exitFullscreen();
    } else if (document.webkitExitFullscreen) {
      document.webkitExitFullscreen();
    } else if (document.mozCancelFullScreen) {
      document.mozCancelFullScreen();
    }
  }
};

// Update button text based on fullscreen state
const updateFullscreenButton = () => {
  if (document.fullscreenElement || document.webkitFullscreenElement || document.mozFullScreenElement) {
    fullscreenBtn.textContent = "â›¶ Exit Fullscreen";
  } else {
    fullscreenBtn.textContent = "â›¶ Fullscreen";
  }
};

document.addEventListener("fullscreenchange", updateFullscreenButton);
document.addEventListener("webkitfullscreenchange", updateFullscreenButton);
document.addEventListener("mozfullscreenchange", updateFullscreenButton);
*/

// End Interaction button - triggers post-study survey
const endInteractionBtn = $("#endInteractionBtn");
endInteractionBtn.onclick = () => {
  // Confirm before ending interaction
  if (confirm('Are you sure you want to end the interaction? You will be asked to complete a post-study survey.')) {
    // End voice conversation if active
    if (window.endVoiceConversation) {
      window.endVoiceConversation();
    }
    
    // Start post-survey
    if (window.startPostSurvey) {
      window.startPostSurvey();
    }
  }
};
</script>
</body>
</html>