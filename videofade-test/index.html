<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8" />
<meta name="viewport" content="width=device-width,initial-scale=1" />
<title>Video Crossfade with Slider (4 clips)</title>
<style>
  html, body {
    background: black;
    /* keep room for fixed controls so they don't overlap the page content */
    padding-bottom: 88px;
  }
  #stage { 
    position: relative; 
    width: 100%; 
    max-width: 960px; 
    aspect-ratio: 16/9; 
    background:#000; 
    margin: 0 auto;
    /* Add top margin to push stage down */
    margin-top: calc((100vh - 88px - (960px * 9/16)) / 2);
}
  #stage video {
    position: absolute; inset: 0; width: 100%; height: 100%;
    object-fit: cover; opacity: 0; pointer-events: none; z-index: 1;
  }
  #stage video.active { opacity: 1; }
  #stage video.on-top { z-index: 2; }

  /* Black box overlay in bottom right corner */
  #blackBox {
    position: absolute;
    bottom: 0;
    right: 0;
    width: 20%;
    height: 20%;
    background: #000;
    z-index: 10;
    pointer-events: none;
  }

  /* Fullscreen styles */
  #stage:fullscreen {
    max-width: 100%;
    width: 100vw;
    height: 100vh;
    margin: 0;
  }
  #stage:-webkit-full-screen {
    max-width: 100%;
    width: 100vw;
    height: 100vh;
    margin: 0;
  }
  #stage:-moz-full-screen {
    max-width: 100%;
    width: 100vw;
    height: 100vh;
    margin: 0;
  }
  /* Controls are fixed to the bottom of the viewport (floating bar) */
  #controls {
    position: fixed;
    left: 0;
    right: 0;
    bottom: 0;
    display: flex;
    gap: .75rem;
    align-items: center;
    justify-content: center;
    padding: 10px 14px;
    background: rgba(0,0,0,0.55);
    backdrop-filter: blur(6px);
    z-index: 50;
    flex-wrap: wrap;
    font: 14px/1.4 system-ui, sans-serif;
    color: #ddd;
  }
  button { padding:.45rem .8rem; border:1px solid #444; background:#111; color:#eee; border-radius:.5rem; cursor:pointer; }
  button:hover { background:#222; }
  input[type="range"] { width: 260px; }
  .val { min-width: 1.5ch; text-align: right; display:inline-block; }

  /* Voice Agent Button */
  #voiceAgentBtn {
    padding: 0.6rem 1.2rem;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    border: 2px solid #8b5cf6;
    color: white;
    font-weight: 600;
    font-size: 15px;
    transition: all 0.3s ease;
    position: relative;
    overflow: hidden;
  }
  #voiceAgentBtn:hover {
    background: linear-gradient(135deg, #764ba2 0%, #667eea 100%);
    transform: translateY(-2px);
    box-shadow: 0 4px 12px rgba(139, 92, 246, 0.4);
  }
  #voiceAgentBtn.active {
    background: linear-gradient(135deg, #ef4444 0%, #dc2626 100%);
    border-color: #ef4444;
    animation: pulse 1.5s infinite;
  }
  #voiceAgentBtn.connected {
    background: linear-gradient(135deg, #10b981 0%, #059669 100%);
    border-color: #10b981;
  }
  @keyframes pulse {
    0%, 100% { opacity: 1; }
    50% { opacity: 0.7; }
  }

  /* Voice Agent Status */
  #voiceStatus {
    font-size: 12px;
    color: #888;
    margin-top: 8px;
    text-align: center;
  }
  #voiceStatus.active { color: #10b981; }
  #voiceStatus.error { color: #ef4444; }
</style>
</head>
<body>

<div id="stage">
  <video id="v0" playsinline muted preload="auto" loop crossorigin="anonymous"></video>
  <video id="v1" playsinline muted preload="auto" loop crossorigin="anonymous"></video>
  <div id="blackBox"></div>
</div>

<div id="controls">
  <button id="play">Play</button>
  <button id="pause">Pause</button>
  <!--
  <button id="fullscreenBtn">â›¶ Fullscreen</button>
  -->
  <label>
    Video:
    <input id="picker" type="range" min="1" max="4" step="1" value="1" />
    <span class="val" id="pickerval">1</span>/4
  </label>
  <button id="voiceAgentBtn">ðŸŽ¤ Talk to Sad Robot</button>
  <button id="toggleTalking">Toggle Talking Mode</button>
  <div id="voiceStatus"></div>
</div>

<script type="module">
// Import dependencies
import { Conversation } from 'https://cdn.jsdelivr.net/npm/@11labs/client/+esm';
import { VideoMixer, intro_video } from './js/videoMixer.js';

// Initialize video mixer
const stage = document.getElementById('stage');
const videoMixer = new VideoMixer(stage);
window.videoMixer = videoMixer; // Make available globally for other modules

// Initialize but don't autoplay
videoMixer.initPlaylistBuffers();

// --- Voice Agent Integration ---
(() => {
  const voiceBtn = document.getElementById("voiceAgentBtn");
  const voiceStatus = document.getElementById("voiceStatus");
  let conversation = null;
  let isConnected = false;

  // Update status message
  function setStatus(message, type = "info") {
    voiceStatus.textContent = message;
    voiceStatus.className = type;
  }

  // Initialize ElevenLabs conversation
  async function initializeVoiceAgent() {
    try {
      setStatus("Connecting to Sad Robot...", "info");
      voiceBtn.classList.add("active");
      voiceBtn.disabled = true;

      // Get signed URL from our backend
      const response = await fetch("/api/get-signed-url");
      if (!response.ok) {
        throw new Error("Failed to get signed URL");
      }

      const { signedUrl } = await response.json();

      setStatus("Starting conversation...", "info");

      // Initialize ElevenLabs conversation using the imported Conversation class
      conversation = await Conversation.startSession({
        signedUrl: signedUrl,
        onConnect: () => {
          console.log("Voice agent connected");
          isConnected = true;
          voiceBtn.classList.remove("active");
          voiceBtn.classList.add("connected");
          voiceBtn.textContent = "ðŸ”´ End Conversation";
          voiceBtn.disabled = false;
          setStatus("Connected! Start talking to the Sad Robot", "active");
        },
        onDisconnect: () => {
          console.log("Voice agent disconnected");
          isConnected = false;
          voiceBtn.classList.remove("active", "connected");
          voiceBtn.textContent = "ðŸŽ¤ Talk to Sad Robot";
          voiceBtn.disabled = false;
          setStatus("", "info");
          conversation = null;
        },
        onError: (error) => {
          console.error("Voice agent error:", error);
          setStatus("Connection error. Please try again.", "error");
          voiceBtn.classList.remove("active", "connected");
          voiceBtn.textContent = "ðŸŽ¤ Talk to Sad Robot";
          voiceBtn.disabled = false;
          isConnected = false;
          conversation = null;
        },
        onMessage: (message) => {
          console.log("Agent message:", message);

          // Store conversation text for analysis at next video loop
          if (message && message.message && window.emotionAnalyzer) {
            const text = message.message;
            window.emotionAnalyzer.storeMessage(text);
          }
        },
      });
    } catch (error) {
      console.error("Failed to initialize voice agent:", error);
      setStatus(`Failed to connect: ${error.message}`, "error");
      voiceBtn.classList.remove("active", "connected");
      voiceBtn.textContent = "ðŸŽ¤ Talk to Sad Robot";
      voiceBtn.disabled = false;
      isConnected = false;
      conversation = null;
    }
  }

  // End conversation
  async function endConversation() {
    if (conversation) {
      try {
        await conversation.endSession();
        conversation = null;
        isConnected = false;
        voiceBtn.classList.remove("active", "connected");
        voiceBtn.textContent = "ðŸŽ¤ Talk to Sad Robot";
        setStatus("", "info");
      } catch (error) {
        console.error("Error ending conversation:", error);
      }
    }
  }

  // Start button click handler
  voiceBtn.addEventListener("click", async () => {
    if (isConnected) {
      await endConversation();
      return;
    }

    // Prevent double clicks
    voiceBtn.disabled = true;
    voiceBtn.classList.add('active');
    setStatus('Preparing...', 'info');

    try {
      // Initialize voice agent after a 5 second delay; do NOT await so the UI flow isn't blocked by the voice init.
      setTimeout(() => {
        console.log('Starting voice agent initialization during intro video...');
        initializeVoiceAgent().catch((err) => {
          console.error('initializeVoiceAgent failed:', err);
        });
      }, 5000);

      // Play the intro one-shot video first. After it finishes, start the playlist.
      setStatus('Playing intro video...', 'info');
      await videoMixer.playOneShot(intro_video).catch((e) => { console.warn('playOneShot failed', e); });

      // Start the usual playlist mechanism
      try { videoMixer.beginPlaylist(); } catch (e) { console.warn('beginPlaylist failed', e); }

    } catch (err) {
      console.error('Error during talk-button flow:', err);
      setStatus('Error starting conversation', 'error');
    } finally {
      voiceBtn.disabled = false;
      voiceBtn.classList.remove('active');
    }
  });

  // Cleanup on page unload
  window.addEventListener("beforeunload", () => {
    if (conversation) {
      conversation.endSession();
    }
  });
})();

// --- UI wiring ---
const $ = (s) => document.querySelector(s);
$("#play").onclick = () => videoMixer.play();
$("#pause").onclick = () => videoMixer.pause();

// Fullscreen toggle
const fullscreenBtn = $("#fullscreenBtn");

/*
fullscreenBtn.onclick = () => {
  if (!document.fullscreenElement && !document.webkitFullscreenElement && !document.mozFullScreenElement) {
    if (stage.requestFullscreen) {
      stage.requestFullscreen();
    } else if (stage.webkitRequestFullscreen) {
      stage.webkitRequestFullscreen();
    } else if (stage.mozRequestFullScreen) {
      stage.mozRequestFullScreen();
    }
  } else {
    if (document.exitFullscreen) {
      document.exitFullscreen();
    } else if (document.webkitExitFullscreen) {
      document.webkitExitFullscreen();
    } else if (document.mozCancelFullScreen) {
      document.mozCancelFullScreen();
    }
  }
};

// Update button text based on fullscreen state
const updateFullscreenButton = () => {
  if (document.fullscreenElement || document.webkitFullscreenElement || document.mozFullScreenElement) {
    fullscreenBtn.textContent = "â›¶ Exit Fullscreen";
  } else {
    fullscreenBtn.textContent = "â›¶ Fullscreen";
  }
};

document.addEventListener("fullscreenchange", updateFullscreenButton);
document.addEventListener("webkitfullscreenchange", updateFullscreenButton);
document.addEventListener("mozfullscreenchange", updateFullscreenButton);
*/

const toggleTalkingBtn = $("#toggleTalking");
toggleTalkingBtn.onclick = () => {
  const newTalkingState = !videoMixer.isTalking;
  videoMixer.setTalking(newTalkingState);
  toggleTalkingBtn.textContent = newTalkingState ? "Exit Talking Mode" : "Enter Talking Mode";
};

const picker = $("#picker");
const pickerval = $("#pickerval");
pickerval.textContent = picker.value;

let pending = null; // simple debounce to avoid stacking fades on rapid drags
picker.addEventListener("input", () => { pickerval.textContent = picker.value; });
picker.addEventListener("change", () => {
  const emotion = parseInt(picker.value, 10); // slider is 1..4

  // Set manual override flag to prevent automatic emotion changes
  if (window.emotionAnalyzer) {
    window.emotionAnalyzer.setManualOverride(true);
    console.log(`[Manual Override] User manually set emotion to ${emotion}`);
  }

  if (pending) { clearTimeout(pending); pending = null; }
  pending = setTimeout(() => {
    // Trigger emotion transition directly with manual source
    if (window.emotionAnalyzer && window.emotionAnalyzer.transitionTo) {
      window.emotionAnalyzer.transitionTo(emotion, 'manual');
    } else {
      // Fallback to direct video control if emotion analyzer not available
      const idx = emotion - 1; // playlist is 0..3
      videoMixer.goTo(idx, { durationMs: 800 });
    }
  }, 0);
});
</script>
</body>
</html>